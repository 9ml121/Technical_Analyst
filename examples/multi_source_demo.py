#!/usr/bin/env python3
"""
å¤šæ•°æ®æºæ•´åˆæ¼”ç¤ºè„šæœ¬

å±•ç¤ºé•¿æœŸæ”¹è¿›æ–¹æ¡ˆçš„æ•ˆæœï¼ŒåŒ…æ‹¬ï¼š
1. å¤šæ•°æ®æºè‡ªåŠ¨åˆ‡æ¢
2. æ•°æ®è´¨é‡å¯¹æ¯”éªŒè¯
3. æ™ºèƒ½ç¼“å­˜æœºåˆ¶
4. æ€§èƒ½ç›‘æ§
"""

import sys
from pathlib import Path
from datetime import datetime, date, timedelta
import time

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
src_path = Path(__file__).parent.parent / "src"
sys.path.insert(0, str(src_path))

try:
    from market_data.fetchers.multi_source_fetcher import MultiSourceFetcher, DataSourceConfig, CacheStrategy
    from market_data.utils.cache_manager import CacheManager, CacheConfig
    from quant_system.utils.logger import get_logger
    logger = get_logger(__name__)
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)


class MultiSourceDemo:
    """å¤šæ•°æ®æºæ•´åˆæ¼”ç¤º"""

    def __init__(self):
        """åˆå§‹åŒ–æ¼”ç¤ºå™¨"""
        # åˆå§‹åŒ–å¤šæ•°æ®æºæ•´åˆå™¨
        self.multi_fetcher = MultiSourceFetcher()

        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        cache_config = CacheConfig(
            strategy=CacheStrategy.MEDIUM,
            ttl_seconds=3600,
            max_size_mb=50,
            compress=True,
            enable_monitoring=True
        )
        self.cache_manager = CacheManager("cache", cache_config)

        # æµ‹è¯•è‚¡ç¥¨ä»£ç 
        self.test_stocks = {
            'Aè‚¡': ['000001', '600000', '300001'],  # å¹³å®‰é“¶è¡Œã€æµ¦å‘é“¶è¡Œã€ç‰¹é”å¾·
            'æ¸¯è‚¡': ['00700', '00941', '02318']     # è…¾è®¯æ§è‚¡ã€ä¸­å›½ç§»åŠ¨ã€ä¸­å›½å¹³å®‰
        }

        # æµ‹è¯•æ—¶é—´èŒƒå›´
        self.end_date = date.today()
        self.start_date = self.end_date - timedelta(days=30)

    def demo_data_source_health_check(self):
        """æ¼”ç¤ºæ•°æ®æºå¥åº·æ£€æŸ¥"""
        print("\n" + "="*80)
        print("ğŸ¥ æ•°æ®æºå¥åº·æ£€æŸ¥æ¼”ç¤º")
        print("="*80)

        print("\nğŸ“Š å¯ç”¨æ•°æ®æº:")
        for market_type in ['a_stock', 'h_stock']:
            available_sources = self.multi_fetcher.get_available_sources(
                market_type)
            print(f"\n{market_type.upper()} å¸‚åœº:")
            for source_name in available_sources:
                config = self.multi_fetcher.data_sources[source_name]
                health_status = self.multi_fetcher.check_source_health(
                    source_name)
                status_icon = "âœ…" if health_status else "âŒ"
                free_icon = "ğŸ†“" if config.is_free else "ğŸ’°"
                cost_info = f"Â¥{config.cost_per_month}/æœˆ" if config.cost_per_month else "å…è´¹"

                print(f"  {status_icon} {free_icon} {source_name}: {cost_info}")
                print(f"     ä¼˜å…ˆçº§: {config.priority}, æ”¯æŒ: Aè‚¡={config.supports_a_stock}, "
                      f"æ¸¯è‚¡={config.supports_h_stock}, ç¾è‚¡={config.supports_us_stock}")

        # è·å–æ€§èƒ½æŠ¥å‘Š
        report = self.multi_fetcher.get_performance_report()
        print(f"\nğŸ“ˆ æ€§èƒ½æŠ¥å‘Š:")
        print(f"   æ€»æ•°æ®æº: {report['total_sources']}")
        print(f"   å¯ç”¨æ•°æ®æº: {report['available_sources']}")
        print(f"   æ¨è: {', '.join(report['recommendations'])}")

    def demo_fallback_mechanism(self):
        """æ¼”ç¤ºæ•…éšœè½¬ç§»æœºåˆ¶"""
        print("\n" + "="*80)
        print("ğŸ”„ æ•…éšœè½¬ç§»æœºåˆ¶æ¼”ç¤º")
        print("="*80)

        for market_name, stock_codes in self.test_stocks.items():
            print(f"\nğŸ›ï¸ æµ‹è¯•å¸‚åœº: {market_name}")
            print("-" * 60)

            for stock_code in stock_codes:
                print(f"\n   æµ‹è¯•è‚¡ç¥¨: {stock_code}")

                # ä½¿ç”¨æ•…éšœè½¬ç§»æœºåˆ¶è·å–æ•°æ®
                data = self.multi_fetcher.get_historical_data_with_fallback(
                    stock_code, self.start_date, self.end_date
                )

                if data:
                    print(f"   âœ… æˆåŠŸè·å– {len(data)} æ¡æ•°æ®")
                    print(f"   æ•°æ®æº: {data[0].get('source', 'unknown')}")

                    # æ˜¾ç¤ºæœ€è¿‘3å¤©çš„æ•°æ®
                    print("   æœ€è¿‘3å¤©æ•°æ®:")
                    for item in data[-3:]:
                        print(f"     {item['date']}: å¼€ç›˜{item['open']:.2f}, "
                              f"æ”¶ç›˜{item['close']:.2f}, æ¶¨è·Œå¹…{item['pct_change']:.2f}%")
                else:
                    print(f"   âŒ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è·å–æ•°æ®")

    def demo_data_quality_comparison(self):
        """æ¼”ç¤ºæ•°æ®è´¨é‡å¯¹æ¯”"""
        print("\n" + "="*80)
        print("ğŸ“Š æ•°æ®è´¨é‡å¯¹æ¯”æ¼”ç¤º")
        print("="*80)

        test_stock = '000001'  # å¹³å®‰é“¶è¡Œ
        print(f"\nğŸ” å¯¹æ¯”è‚¡ç¥¨: {test_stock}")

        # æ¯”è¾ƒä¸åŒæ•°æ®æºçš„æ•°æ®è´¨é‡
        quality_metrics = self.multi_fetcher.compare_data_quality(
            test_stock, self.start_date, self.end_date
        )

        if quality_metrics:
            print("\nğŸ“ˆ æ•°æ®è´¨é‡è¯„åˆ†:")
            print("-" * 80)
            print(
                f"{'æ•°æ®æº':<12} {'å®Œæ•´æ€§':<8} {'å‡†ç¡®æ€§':<8} {'åŠæ—¶æ€§':<8} {'ä¸€è‡´æ€§':<8} {'ç»¼åˆè¯„åˆ†':<8}")
            print("-" * 80)

            for source_name, metrics in quality_metrics.items():
                print(f"{source_name:<12} {metrics.completeness:<8.2f} {metrics.accuracy:<8.2f} "
                      f"{metrics.timeliness:<8.2f} {metrics.consistency:<8.2f} {metrics.overall_score:<8.2f}")

            # æ‰¾å‡ºæœ€ä½³æ•°æ®æº
            best_source = max(quality_metrics.items(),
                              key=lambda x: x[1].overall_score)
            print(
                f"\nğŸ† æœ€ä½³æ•°æ®æº: {best_source[0]} (è¯„åˆ†: {best_source[1].overall_score:.2f})")
        else:
            print("âŒ æ— æ³•è·å–æ•°æ®è´¨é‡å¯¹æ¯”ä¿¡æ¯")

    def demo_cache_mechanism(self):
        """æ¼”ç¤ºç¼“å­˜æœºåˆ¶"""
        print("\n" + "="*80)
        print("ğŸ’¾ æ™ºèƒ½ç¼“å­˜æœºåˆ¶æ¼”ç¤º")
        print("="*80)

        test_stock = '600000'  # æµ¦å‘é“¶è¡Œ

        print(f"\nğŸ“Š æµ‹è¯•è‚¡ç¥¨: {test_stock}")

        # ç¬¬ä¸€æ¬¡è·å–æ•°æ®ï¼ˆæ— ç¼“å­˜ï¼‰
        print("\n1ï¸âƒ£ ç¬¬ä¸€æ¬¡è·å–æ•°æ® (æ— ç¼“å­˜):")
        start_time = time.time()
        data1 = self.multi_fetcher.get_historical_data_with_fallback(
            test_stock, self.start_date, self.end_date
        )
        time1 = time.time() - start_time

        if data1:
            print(f"   âœ… è·å–æˆåŠŸï¼Œè€—æ—¶: {time1:.2f}ç§’")

            # ç¼“å­˜æ•°æ®
            cache_strategy = CacheStrategy.MEDIUM
            cache_success = self.cache_manager.set(
                'historical_data', test_stock, data1, cache_strategy,
                start_date=self.start_date.isoformat(),
                end_date=self.end_date.isoformat()
            )

            if cache_success:
                print(f"   ğŸ’¾ æ•°æ®å·²ç¼“å­˜ (ç­–ç•¥: {cache_strategy.value})")
            else:
                print("   âŒ ç¼“å­˜å¤±è´¥")

        # ç¬¬äºŒæ¬¡è·å–æ•°æ®ï¼ˆæœ‰ç¼“å­˜ï¼‰
        print("\n2ï¸âƒ£ ç¬¬äºŒæ¬¡è·å–æ•°æ® (æœ‰ç¼“å­˜):")
        start_time = time.time()

        # å…ˆå°è¯•ä»ç¼“å­˜è·å–
        cached_data = self.cache_manager.get(
            'historical_data', test_stock,
            start_date=self.start_date.isoformat(),
            end_date=self.end_date.isoformat()
        )

        if cached_data:
            print(f"   âœ… ä»ç¼“å­˜è·å–æˆåŠŸï¼Œè€—æ—¶: {time.time() - start_time:.2f}ç§’")
            data2 = cached_data
        else:
            print("   âš ï¸ ç¼“å­˜æœªå‘½ä¸­ï¼Œé‡æ–°è·å–æ•°æ®")
            data2 = self.multi_fetcher.get_historical_data_with_fallback(
                test_stock, self.start_date, self.end_date
            )
            print(f"   âœ… é‡æ–°è·å–æˆåŠŸï¼Œè€—æ—¶: {time.time() - start_time:.2f}ç§’")

        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        cache_stats = self.cache_manager.get_stats()
        print(f"\nğŸ“ˆ ç¼“å­˜ç»Ÿè®¡:")
        print(f"   æ€»è¯·æ±‚æ•°: {cache_stats['stats']['total_requests']}")
        print(f"   ç¼“å­˜å‘½ä¸­: {cache_stats['stats']['cache_hits']}")
        print(f"   ç¼“å­˜æœªå‘½ä¸­: {cache_stats['stats']['cache_misses']}")
        print(f"   å‘½ä¸­ç‡: {cache_stats['stats']['hit_rate']:.2%}")
        print(f"   ç¼“å­˜å¤§å°: {cache_stats['stats']['total_size_mb']:.2f}MB")
        print(f"   ç¼“å­˜é¡¹æ•°: {cache_stats['cache_count']}")

    def demo_performance_optimization(self):
        """æ¼”ç¤ºæ€§èƒ½ä¼˜åŒ–"""
        print("\n" + "="*80)
        print("âš¡ æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º")
        print("="*80)

        # æ‰¹é‡è·å–æ•°æ®
        print("\nğŸ“¦ æ‰¹é‡æ•°æ®è·å–æµ‹è¯•:")
        all_stocks = []
        for stocks in self.test_stocks.values():
            all_stocks.extend(stocks)

        print(f"   æµ‹è¯•è‚¡ç¥¨æ•°é‡: {len(all_stocks)}")

        # ä¸ä½¿ç”¨ç¼“å­˜
        print("\nğŸ”„ ä¸ä½¿ç”¨ç¼“å­˜:")
        start_time = time.time()
        success_count = 0

        for stock_code in all_stocks:
            data = self.multi_fetcher.get_historical_data_with_fallback(
                stock_code, self.start_date, self.end_date
            )
            if data:
                success_count += 1

        time_without_cache = time.time() - start_time
        print(f"   æˆåŠŸè·å–: {success_count}/{len(all_stocks)}")
        print(f"   æ€»è€—æ—¶: {time_without_cache:.2f}ç§’")
        print(f"   å¹³å‡è€—æ—¶: {time_without_cache/len(all_stocks):.2f}ç§’/åª")

        # ä½¿ç”¨ç¼“å­˜
        print("\nğŸ’¾ ä½¿ç”¨ç¼“å­˜:")
        start_time = time.time()
        success_count = 0

        for stock_code in all_stocks:
            # å…ˆå°è¯•ä»ç¼“å­˜è·å–
            cached_data = self.cache_manager.get(
                'historical_data', stock_code,
                start_date=self.start_date.isoformat(),
                end_date=self.end_date.isoformat()
            )

            if cached_data:
                success_count += 1
            else:
                # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®æºè·å–
                data = self.multi_fetcher.get_historical_data_with_fallback(
                    stock_code, self.start_date, self.end_date
                )
                if data:
                    success_count += 1
                    # ç¼“å­˜æ•°æ®
                    self.cache_manager.set(
                        'historical_data', stock_code, data, CacheStrategy.MEDIUM,
                        start_date=self.start_date.isoformat(),
                        end_date=self.end_date.isoformat()
                    )

        time_with_cache = time.time() - start_time
        print(f"   æˆåŠŸè·å–: {success_count}/{len(all_stocks)}")
        print(f"   æ€»è€—æ—¶: {time_with_cache:.2f}ç§’")
        print(f"   å¹³å‡è€—æ—¶: {time_with_cache/len(all_stocks):.2f}ç§’/åª")

        # æ€§èƒ½æå‡
        if time_without_cache > 0:
            improvement = (time_without_cache - time_with_cache) / \
                time_without_cache * 100
            print(f"   æ€§èƒ½æå‡: {improvement:.1f}%")

    def demo_cost_analysis(self):
        """æ¼”ç¤ºæˆæœ¬åˆ†æ"""
        print("\n" + "="*80)
        print("ğŸ’° æˆæœ¬åˆ†ææ¼”ç¤º")
        print("="*80)

        print("\nğŸ“Š æ•°æ®æºæˆæœ¬å¯¹æ¯”:")
        print("-" * 80)
        print(f"{'æ•°æ®æº':<15} {'è´¹ç”¨':<12} {'Aè‚¡':<6} {'æ¸¯è‚¡':<6} {'ç¾è‚¡':<6} {'æ¨èæŒ‡æ•°':<8}")
        print("-" * 80)

        cost_data = [
            ('akshare', 'å…è´¹', 'âœ…', 'âš ï¸', 'âŒ', 'â­â­â­â­â­'),
            ('ä¸œæ–¹è´¢å¯Œ', 'å…è´¹', 'âœ…', 'âŒ', 'âŒ', 'â­â­â­â­'),
            ('Yahoo Finance', 'å…è´¹', 'âš ï¸', 'âœ…', 'âœ…', 'â­â­â­â­'),
            ('TushareåŸºç¡€ç‰ˆ', 'Â¥199/æœˆ', 'âœ…', 'âš ï¸', 'âŒ', 'â­â­â­â­â­'),
            ('èšå®½åŸºç¡€ç‰ˆ', 'Â¥99/æœˆ', 'âœ…', 'âœ…', 'âœ…', 'â­â­â­â­'),
            ('ä¸‡å¾—ä¸ªäººç‰ˆ', 'Â¥299/æœˆ', 'âœ…', 'âœ…', 'âœ…', 'â­â­â­â­'),
        ]

        for source, cost, a_stock, h_stock, us_stock, rating in cost_data:
            print(
                f"{source:<15} {cost:<12} {a_stock:<6} {h_stock:<6} {us_stock:<6} {rating:<8}")

        print("\nğŸ’¡ æ¨èæ–¹æ¡ˆ:")
        print("1. ğŸ†“ çº¯å…è´¹æ–¹æ¡ˆ: akshare + Yahoo Finance (æœˆè´¹ç”¨: Â¥0)")
        print("2. ğŸ’° æ··åˆæ–¹æ¡ˆ: akshare + TushareåŸºç¡€ç‰ˆ + Yahoo Finance (æœˆè´¹ç”¨: Â¥199)")
        print("3. ğŸ’ ä¸“ä¸šæ–¹æ¡ˆ: Tushareä¸“ä¸šç‰ˆ + èšå®½ä¸“ä¸šç‰ˆ + ä¸‡å¾—æ•°æ® (æœˆè´¹ç”¨: Â¥697)")

    def run_all_demos(self):
        """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
        print("ğŸš€ å¤šæ•°æ®æºæ•´åˆç³»ç»Ÿæ¼”ç¤º")
        print("=" * 80)
        print(f"æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # è¿è¡Œå„ä¸ªæ¼”ç¤º
        self.demo_data_source_health_check()
        self.demo_fallback_mechanism()
        self.demo_data_quality_comparison()
        self.demo_cache_mechanism()
        self.demo_performance_optimization()
        self.demo_cost_analysis()

        print("\n" + "="*80)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆ!")
        print("="*80)
        print("\nğŸ“‹ é•¿æœŸæ”¹è¿›æ–¹æ¡ˆæ€»ç»“:")
        print("âœ… å¤šæ•°æ®æºè‡ªåŠ¨åˆ‡æ¢ - æé«˜æ•°æ®å¯ç”¨æ€§")
        print("âœ… æ•°æ®è´¨é‡å¯¹æ¯”éªŒè¯ - ç¡®ä¿æ•°æ®å‡†ç¡®æ€§")
        print("âœ… æ™ºèƒ½ç¼“å­˜æœºåˆ¶ - æå‡æ€§èƒ½")
        print("âœ… æˆæœ¬æ•ˆç›Šåˆ†æ - ä¼˜åŒ–èµ„æºé…ç½®")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©åˆé€‚çš„ä»˜è´¹æ•°æ®æº")
        print("2. æŒç»­ç›‘æ§æ•°æ®æºå¥åº·çŠ¶æ€")
        print("3. å®šæœŸä¼˜åŒ–ç¼“å­˜ç­–ç•¥")
        print("4. å»ºç«‹æ•°æ®è´¨é‡ç›‘æ§ä½“ç³»")


def main():
    """ä¸»å‡½æ•°"""
    demo = MultiSourceDemo()
    demo.run_all_demos()


if __name__ == "__main__":
    main()
