#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•ç³»ç»Ÿå„ä¸ªç»„ä»¶çš„æ€§èƒ½è¡¨ç°
"""

import sys
import time
import random
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
src_path = Path(__file__).parent.parent / "src"
sys.path.insert(0, str(src_path))

from quant_system.utils.performance import (
    performance_monitor, start_performance_monitoring, stop_performance_monitoring,
    print_performance_report, performance_timer, performance_context
)
from quant_system.utils.cache import cache_manager, cache_result
from quant_system.utils.concurrent import parallel_map, parallel_process
from market_data.processors.data_processor import MarketDataProcessor

def generate_mock_stock_data(count: int = 1000):
    """ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®"""
    stocks = []
    
    for i in range(count):
        stock = {
            'code': f"{random.randint(0, 999):03d}{random.randint(0, 999):03d}",
            'name': f"è‚¡ç¥¨{i+1}",
            'price': round(random.uniform(5, 100), 2),
            'open': round(random.uniform(5, 100), 2),
            'high': round(random.uniform(5, 100), 2),
            'low': round(random.uniform(5, 100), 2),
            'close': round(random.uniform(5, 100), 2),
            'volume': random.randint(100000, 10000000),
            'amount': random.randint(1000000, 100000000),
            'pct_change': round(random.uniform(-0.1, 0.1), 4),
            'change': round(random.uniform(-5, 5), 2),
            'turnover_rate': round(random.uniform(0.01, 0.2), 4),
            'market_cap': random.randint(1000000000, 100000000000)
        }
        stocks.append(stock)
    
    return stocks

@performance_timer
def test_data_processing_performance():
    """æµ‹è¯•æ•°æ®å¤„ç†æ€§èƒ½"""
    print("\nğŸ”§ æµ‹è¯•æ•°æ®å¤„ç†æ€§èƒ½...")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_sizes = [100, 500, 1000, 5000]
    processor = MarketDataProcessor(enable_parallel=True)
    
    results = {}
    
    for size in test_sizes:
        print(f"\n  æµ‹è¯•æ•°æ®é‡: {size}")
        
        # ç”Ÿæˆæ•°æ®
        with performance_context(f"generate_data_{size}"):
            mock_data = generate_mock_stock_data(size)
        
        # æµ‹è¯•æ•°æ®æ¸…æ´—
        with performance_context(f"clean_data_{size}"):
            cleaned_data = processor.clean_stock_data(mock_data)
        
        # æµ‹è¯•æ•°æ®ç­›é€‰
        filters = {
            'min_price': 10.0,
            'min_volume': 1000000,
            'min_pct_change': 0.0
        }
        
        with performance_context(f"filter_data_{size}"):
            filtered_data = processor.filter_stocks(cleaned_data, filters)
        
        # æµ‹è¯•æ•°æ®æ’åº
        with performance_context(f"sort_data_{size}"):
            sorted_data = processor.sort_stocks(filtered_data, 'pct_change')
        
        results[size] = {
            'original': len(mock_data),
            'cleaned': len(cleaned_data),
            'filtered': len(filtered_data),
            'sorted': len(sorted_data)
        }
        
        print(f"    åŸå§‹æ•°æ®: {results[size]['original']}")
        print(f"    æ¸…æ´—å: {results[size]['cleaned']}")
        print(f"    ç­›é€‰å: {results[size]['filtered']}")
        print(f"    æ’åºå: {results[size]['sorted']}")
    
    return results

@performance_timer
def test_parallel_processing_performance():
    """æµ‹è¯•å¹¶è¡Œå¤„ç†æ€§èƒ½"""
    print("\nâš¡ æµ‹è¯•å¹¶è¡Œå¤„ç†æ€§èƒ½...")
    
    def cpu_intensive_task(n):
        """CPUå¯†é›†å‹ä»»åŠ¡"""
        result = 0
        for i in range(n * 1000):
            result += i ** 2
        return result
    
    def io_intensive_task(delay):
        """IOå¯†é›†å‹ä»»åŠ¡"""
        time.sleep(delay)
        return f"Task completed after {delay}s"
    
    # æµ‹è¯•CPUå¯†é›†å‹ä»»åŠ¡
    print("\n  CPUå¯†é›†å‹ä»»åŠ¡æµ‹è¯•:")
    cpu_tasks = [100, 200, 300, 400, 500]
    
    # ä¸²è¡Œæ‰§è¡Œ
    start_time = time.time()
    serial_results = [cpu_intensive_task(n) for n in cpu_tasks]
    serial_time = time.time() - start_time
    print(f"    ä¸²è¡Œæ‰§è¡Œæ—¶é—´: {serial_time:.2f}s")
    
    # å¹¶è¡Œæ‰§è¡Œï¼ˆçº¿ç¨‹ï¼‰
    start_time = time.time()
    parallel_results_thread = parallel_map(cpu_intensive_task, cpu_tasks, use_processes=False)
    parallel_time_thread = time.time() - start_time
    print(f"    å¹¶è¡Œæ‰§è¡Œæ—¶é—´ï¼ˆçº¿ç¨‹ï¼‰: {parallel_time_thread:.2f}s")
    
    # å¹¶è¡Œæ‰§è¡Œï¼ˆè¿›ç¨‹ï¼‰
    start_time = time.time()
    parallel_results_process = parallel_map(cpu_intensive_task, cpu_tasks, use_processes=True)
    parallel_time_process = time.time() - start_time
    print(f"    å¹¶è¡Œæ‰§è¡Œæ—¶é—´ï¼ˆè¿›ç¨‹ï¼‰: {parallel_time_process:.2f}s")
    
    print(f"    çº¿ç¨‹åŠ é€Ÿæ¯”: {serial_time / parallel_time_thread:.2f}x")
    print(f"    è¿›ç¨‹åŠ é€Ÿæ¯”: {serial_time / parallel_time_process:.2f}x")
    
    # æµ‹è¯•IOå¯†é›†å‹ä»»åŠ¡
    print("\n  IOå¯†é›†å‹ä»»åŠ¡æµ‹è¯•:")
    io_tasks = [0.1, 0.1, 0.1, 0.1, 0.1]  # 5ä¸ª0.1ç§’çš„ä»»åŠ¡
    
    # ä¸²è¡Œæ‰§è¡Œ
    start_time = time.time()
    serial_io_results = [io_intensive_task(delay) for delay in io_tasks]
    serial_io_time = time.time() - start_time
    print(f"    ä¸²è¡Œæ‰§è¡Œæ—¶é—´: {serial_io_time:.2f}s")
    
    # å¹¶è¡Œæ‰§è¡Œ
    start_time = time.time()
    parallel_io_results = parallel_map(io_intensive_task, io_tasks, use_processes=False)
    parallel_io_time = time.time() - start_time
    print(f"    å¹¶è¡Œæ‰§è¡Œæ—¶é—´: {parallel_io_time:.2f}s")
    print(f"    IOåŠ é€Ÿæ¯”: {serial_io_time / parallel_io_time:.2f}x")

@cache_result(ttl=60)
def expensive_calculation(n):
    """æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—"""
    time.sleep(0.1)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
    return sum(i ** 2 for i in range(n))

@performance_timer
def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\nğŸ’¾ æµ‹è¯•ç¼“å­˜æ€§èƒ½...")
    
    test_values = [100, 200, 300, 100, 200, 400, 100]  # åŒ…å«é‡å¤å€¼
    
    # ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆæ— ç¼“å­˜ï¼‰
    print("\n  ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆæ— ç¼“å­˜ï¼‰:")
    start_time = time.time()
    results1 = []
    for value in test_values:
        result = expensive_calculation(value)
        results1.append(result)
    first_time = time.time() - start_time
    print(f"    æ‰§è¡Œæ—¶é—´: {first_time:.2f}s")
    
    # ç¬¬äºŒæ¬¡æ‰§è¡Œï¼ˆæœ‰ç¼“å­˜ï¼‰
    print("\n  ç¬¬äºŒæ¬¡æ‰§è¡Œï¼ˆæœ‰ç¼“å­˜ï¼‰:")
    start_time = time.time()
    results2 = []
    for value in test_values:
        result = expensive_calculation(value)
        results2.append(result)
    second_time = time.time() - start_time
    print(f"    æ‰§è¡Œæ—¶é—´: {second_time:.2f}s")
    
    print(f"    ç¼“å­˜åŠ é€Ÿæ¯”: {first_time / second_time:.2f}x")
    
    # éªŒè¯ç»“æœä¸€è‡´æ€§
    assert results1 == results2, "ç¼“å­˜ç»“æœä¸ä¸€è‡´"
    print("    âœ… ç¼“å­˜ç»“æœéªŒè¯é€šè¿‡")
    
    # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    print("\n  ç¼“å­˜ç»Ÿè®¡:")
    cache_manager.print_stats()

@performance_timer
def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("\nğŸ’¾ æµ‹è¯•å†…å­˜ä½¿ç”¨...")
    
    import psutil
    process = psutil.Process()
    
    # åˆå§‹å†…å­˜
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f"  åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.1f}MB")
    
    # åˆ›å»ºå¤§é‡æ•°æ®
    large_data = []
    for i in range(10):
        batch_data = generate_mock_stock_data(1000)
        large_data.extend(batch_data)
        
        current_memory = process.memory_info().rss / 1024 / 1024
        print(f"    æ‰¹æ¬¡ {i+1}: {current_memory:.1f}MB (+{current_memory - initial_memory:.1f}MB)")
    
    # å¤„ç†æ•°æ®
    processor = MarketDataProcessor()
    
    print("\n  å¤„ç†å¤§é‡æ•°æ®...")
    processed_memory_start = process.memory_info().rss / 1024 / 1024
    
    cleaned_data = processor.clean_stock_data(large_data)
    
    processed_memory_end = process.memory_info().rss / 1024 / 1024
    print(f"    å¤„ç†åå†…å­˜: {processed_memory_end:.1f}MB")
    print(f"    å¤„ç†å¢é‡: {processed_memory_end - processed_memory_start:.1f}MB")
    
    # æ¸…ç†æ•°æ®
    del large_data
    del cleaned_data
    
    import gc
    gc.collect()
    
    final_memory = process.memory_info().rss / 1024 / 1024
    print(f"    æ¸…ç†åå†…å­˜: {final_memory:.1f}MB")

def test_system_performance():
    """ç³»ç»Ÿæ€§èƒ½ç»¼åˆæµ‹è¯•"""
    print("ğŸš€ é‡åŒ–æŠ•èµ„ç³»ç»Ÿæ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # å¯åŠ¨æ€§èƒ½ç›‘æ§
    start_performance_monitoring(interval=0.5)
    
    try:
        # è¿è¡Œå„é¡¹æ€§èƒ½æµ‹è¯•
        test_data_processing_performance()
        test_parallel_processing_performance()
        test_cache_performance()
        test_memory_usage()
        
        # æ˜¾ç¤ºæ€§èƒ½æŠ¥å‘Š
        print("\nğŸ“Š æ€§èƒ½ç›‘æ§æŠ¥å‘Š:")
        print_performance_report()
        
    finally:
        # åœæ­¢æ€§èƒ½ç›‘æ§
        stop_performance_monitoring()

def benchmark_comparison():
    """åŸºå‡†æµ‹è¯•å¯¹æ¯”"""
    print("\nğŸ“ˆ åŸºå‡†æµ‹è¯•å¯¹æ¯”")
    print("=" * 40)
    
    # æ•°æ®å¤„ç†åŸºå‡†æµ‹è¯•
    data_sizes = [100, 500, 1000, 2000]
    
    print("\næ•°æ®å¤„ç†æ€§èƒ½å¯¹æ¯”:")
    print(f"{'æ•°æ®é‡':<8} {'ä¸²è¡Œ(ms)':<10} {'å¹¶è¡Œ(ms)':<10} {'åŠ é€Ÿæ¯”':<8}")
    print("-" * 40)
    
    for size in data_sizes:
        mock_data = generate_mock_stock_data(size)
        
        # ä¸²è¡Œå¤„ç†
        processor_serial = MarketDataProcessor(enable_parallel=False)
        start_time = time.time()
        processor_serial.clean_stock_data(mock_data)
        serial_time = (time.time() - start_time) * 1000
        
        # å¹¶è¡Œå¤„ç†
        processor_parallel = MarketDataProcessor(enable_parallel=True)
        start_time = time.time()
        processor_parallel.clean_stock_data(mock_data)
        parallel_time = (time.time() - start_time) * 1000
        
        speedup = serial_time / parallel_time if parallel_time > 0 else 1.0
        
        print(f"{size:<8} {serial_time:<10.1f} {parallel_time:<10.1f} {speedup:<8.2f}x")

def stress_test():
    """å‹åŠ›æµ‹è¯•"""
    print("\nğŸ”¥ å‹åŠ›æµ‹è¯•")
    print("=" * 30)
    
    # å¤§æ•°æ®é‡æµ‹è¯•
    large_sizes = [5000, 10000, 20000]
    
    for size in large_sizes:
        print(f"\næµ‹è¯•æ•°æ®é‡: {size}")
        
        try:
            with performance_context(f"stress_test_{size}"):
                # ç”Ÿæˆå¤§é‡æ•°æ®
                mock_data = generate_mock_stock_data(size)
                
                # æ•°æ®å¤„ç†
                processor = MarketDataProcessor(enable_parallel=True)
                cleaned_data = processor.clean_stock_data(mock_data)
                
                # å¤æ‚ç­›é€‰
                filters = {
                    'min_price': 10.0,
                    'max_price': 80.0,
                    'min_volume': 1000000,
                    'min_pct_change': -0.05,
                    'max_pct_change': 0.05
                }
                filtered_data = processor.filter_stocks(cleaned_data, filters)
                
                # æ’åº
                sorted_data = processor.sort_stocks(filtered_data, 'market_cap')
                
                print(f"  âœ… æˆåŠŸå¤„ç† {len(sorted_data)} åªè‚¡ç¥¨")
                
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹æ€§èƒ½æµ‹è¯•...")
    
    # ç³»ç»Ÿæ€§èƒ½æµ‹è¯•
    test_system_performance()
    
    # åŸºå‡†æµ‹è¯•å¯¹æ¯”
    benchmark_comparison()
    
    # å‹åŠ›æµ‹è¯•
    stress_test()
    
    print("\nğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    print("  1. å¯¹äºå¤§æ•°æ®é›†ï¼Œå¯ç”¨å¹¶è¡Œå¤„ç†å¯æ˜¾è‘—æå‡æ€§èƒ½")
    print("  2. åˆç†ä½¿ç”¨ç¼“å­˜å¯ä»¥é¿å…é‡å¤è®¡ç®—")
    print("  3. ç›‘æ§å†…å­˜ä½¿ç”¨ï¼ŒåŠæ—¶æ¸…ç†ä¸éœ€è¦çš„æ•°æ®")
    print("  4. CPUå¯†é›†å‹ä»»åŠ¡é€‚åˆä½¿ç”¨è¿›ç¨‹æ± ")
    print("  5. IOå¯†é›†å‹ä»»åŠ¡é€‚åˆä½¿ç”¨çº¿ç¨‹æ± ")

if __name__ == "__main__":
    main()
