"""
ç¼“å­˜ç³»ç»Ÿ

æä¾›å¤šå±‚æ¬¡ç¼“å­˜æœºåˆ¶ï¼Œæå‡ç³»ç»Ÿæ€§èƒ½
"""

import time
import pickle
import hashlib
import threading
from typing import Any, Dict, Optional, Callable, Union, Tuple
from functools import wraps
from collections import OrderedDict
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class LRUCache:
    """LRU (Least Recently Used) ç¼“å­˜å®ç°"""

    def __init__(self, max_size: int = 1000, ttl: Optional[float] = None):
        """
        åˆå§‹åŒ–LRUç¼“å­˜

        Args:
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
            ttl: ç”Ÿå­˜æ—¶é—´(ç§’)ï¼ŒNoneè¡¨ç¤ºæ°¸ä¸è¿‡æœŸ
        """
        self.max_size = max_size
        self.ttl = ttl
        self.cache = OrderedDict()
        self.timestamps = {}
        self.lock = threading.RLock()
        self.hits = 0
        self.misses = 0

    def _is_expired(self, key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜é¡¹æ˜¯å¦è¿‡æœŸ"""
        if self.ttl is None:
            return False

        timestamp = self.timestamps.get(key)
        if timestamp is None:
            return True

        return time.time() - timestamp > self.ttl

    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        with self.lock:
            if key not in self.cache:
                self.misses += 1
                return None

            if self._is_expired(key):
                self._remove(key)
                self.misses += 1
                return None

            # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
            value = self.cache.pop(key)
            self.cache[key] = value
            self.hits += 1
            return value

    def put(self, key: str, value: Any):
        """è®¾ç½®ç¼“å­˜å€¼"""
        with self.lock:
            if key in self.cache:
                # æ›´æ–°ç°æœ‰å€¼
                self.cache.pop(key)
            elif len(self.cache) >= self.max_size:
                # ç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„é¡¹
                oldest_key = next(iter(self.cache))
                self._remove(oldest_key)

            self.cache[key] = value
            if self.ttl is not None:
                self.timestamps[key] = time.time()

    def _remove(self, key: str):
        """ç§»é™¤ç¼“å­˜é¡¹"""
        self.cache.pop(key, None)
        self.timestamps.pop(key, None)

    def remove(self, key: str) -> bool:
        """æ‰‹åŠ¨ç§»é™¤ç¼“å­˜é¡¹"""
        with self.lock:
            if key in self.cache:
                self._remove(key)
                return True
            return False

    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.lock:
            self.cache.clear()
            self.timestamps.clear()
            self.hits = 0
            self.misses = 0

    def size(self) -> int:
        """è·å–ç¼“å­˜å¤§å°"""
        with self.lock:
            return len(self.cache)

    def hit_rate(self) -> float:
        """è·å–ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0

    def stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            return {
                'size': len(self.cache),
                'max_size': self.max_size,
                'hits': self.hits,
                'misses': self.misses,
                'hit_rate': self.hit_rate(),
                'ttl': self.ttl
            }


class FileCache:
    """æ–‡ä»¶ç¼“å­˜å®ç°"""

    def __init__(self, cache_dir: str = "cache", max_size_mb: int = 100):
        """
        åˆå§‹åŒ–æ–‡ä»¶ç¼“å­˜

        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            max_size_mb: æœ€å¤§ç¼“å­˜å¤§å°(MB)
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.max_size_bytes = max_size_mb * 1024 * 1024
        self.lock = threading.Lock()

    def _get_cache_path(self, key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        # ä½¿ç”¨MD5å“ˆå¸Œé¿å…æ–‡ä»¶åè¿‡é•¿æˆ–åŒ…å«ç‰¹æ®Šå­—ç¬¦
        hash_key = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{hash_key}.cache"

    def _get_meta_path(self, key: str) -> Path:
        """è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
        hash_key = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{hash_key}.meta"

    def get(self, key: str, ttl: Optional[float] = None) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        cache_path = self._get_cache_path(key)
        meta_path = self._get_meta_path(key)

        if not cache_path.exists() or not meta_path.exists():
            return None

        try:
            # æ£€æŸ¥TTL
            if ttl is not None:
                meta_stat = meta_path.stat()
                if time.time() - meta_stat.st_mtime > ttl:
                    self.remove(key)
                    return None

            # è¯»å–ç¼“å­˜æ•°æ®
            with open(cache_path, 'rb') as f:
                return pickle.load(f)

        except Exception as e:
            logger.warning(f"è¯»å–æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")
            self.remove(key)
            return None

    def put(self, key: str, value: Any):
        """è®¾ç½®ç¼“å­˜å€¼"""
        cache_path = self._get_cache_path(key)
        meta_path = self._get_meta_path(key)

        try:
            with self.lock:
                # æ£€æŸ¥ç¼“å­˜å¤§å°
                self._cleanup_if_needed()

                # å†™å…¥ç¼“å­˜æ•°æ®
                with open(cache_path, 'wb') as f:
                    pickle.dump(value, f)

                # å†™å…¥å…ƒæ•°æ®
                with open(meta_path, 'w') as f:
                    f.write(f"key: {key}\n")
                    f.write(f"timestamp: {time.time()}\n")

        except Exception as e:
            logger.error(f"å†™å…¥æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")

    def remove(self, key: str) -> bool:
        """ç§»é™¤ç¼“å­˜é¡¹"""
        cache_path = self._get_cache_path(key)
        meta_path = self._get_meta_path(key)

        removed = False
        for path in [cache_path, meta_path]:
            if path.exists():
                try:
                    path.unlink()
                    removed = True
                except Exception as e:
                    logger.warning(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

        return removed

    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        try:
            for file_path in self.cache_dir.glob("*.cache"):
                file_path.unlink()
            for file_path in self.cache_dir.glob("*.meta"):
                file_path.unlink()
        except Exception as e:
            logger.error(f"æ¸…ç©ºæ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")

    def _cleanup_if_needed(self):
        """å¦‚æœéœ€è¦åˆ™æ¸…ç†ç¼“å­˜"""
        total_size = sum(
            f.stat().st_size
            for f in self.cache_dir.glob("*.cache")
            if f.is_file()
        )

        if total_size > self.max_size_bytes:
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„æ–‡ä»¶
            cache_files = list(self.cache_dir.glob("*.cache"))
            cache_files.sort(key=lambda x: x.stat().st_mtime)

            for cache_file in cache_files:
                if total_size <= self.max_size_bytes * 0.8:  # æ¸…ç†åˆ°80%
                    break

                try:
                    file_size = cache_file.stat().st_size
                    cache_file.unlink()

                    # åˆ é™¤å¯¹åº”çš„å…ƒæ•°æ®æ–‡ä»¶
                    meta_file = cache_file.with_suffix('.meta')
                    if meta_file.exists():
                        meta_file.unlink()

                    total_size -= file_size

                except Exception as e:
                    logger.warning(f"æ¸…ç†ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        cache_files = list(self.cache_dir.glob("*.cache"))
        total_size = sum(f.stat().st_size for f in cache_files if f.is_file())

        return {
            'file_count': len(cache_files),
            'total_size_mb': total_size / 1024 / 1024,
            'max_size_mb': self.max_size_bytes / 1024 / 1024,
            'cache_dir': str(self.cache_dir)
        }


class MultiLevelCache:
    """å¤šçº§ç¼“å­˜ç³»ç»Ÿ"""

    def __init__(self,
                 l1_size: int = 1000,
                 l1_ttl: Optional[float] = 300,  # 5åˆ†é’Ÿ
                 l2_size_mb: int = 100,
                 l2_ttl: Optional[float] = 3600):  # 1å°æ—¶
        """
        åˆå§‹åŒ–å¤šçº§ç¼“å­˜

        Args:
            l1_size: L1ç¼“å­˜å¤§å°ï¼ˆå†…å­˜ï¼‰
            l1_ttl: L1ç¼“å­˜TTL
            l2_size_mb: L2ç¼“å­˜å¤§å°ï¼ˆæ–‡ä»¶ï¼‰
            l2_ttl: L2ç¼“å­˜TTL
        """
        self.l1_cache = LRUCache(max_size=l1_size, ttl=l1_ttl)
        self.l2_cache = FileCache(max_size_mb=l2_size_mb)
        self.l2_ttl = l2_ttl

    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        # å…ˆæŸ¥L1ç¼“å­˜
        value = self.l1_cache.get(key)
        if value is not None:
            return value

        # å†æŸ¥L2ç¼“å­˜
        value = self.l2_cache.get(key, self.l2_ttl)
        if value is not None:
            # æå‡åˆ°L1ç¼“å­˜
            self.l1_cache.put(key, value)
            return value

        return None

    def put(self, key: str, value: Any):
        """è®¾ç½®ç¼“å­˜å€¼"""
        # åŒæ—¶å†™å…¥L1å’ŒL2ç¼“å­˜
        self.l1_cache.put(key, value)
        self.l2_cache.put(key, value)

    def remove(self, key: str) -> bool:
        """ç§»é™¤ç¼“å­˜é¡¹"""
        l1_removed = self.l1_cache.remove(key)
        l2_removed = self.l2_cache.remove(key)
        return l1_removed or l2_removed

    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.l1_cache.clear()
        self.l2_cache.clear()

    def stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'l1_cache': self.l1_cache.stats(),
            'l2_cache': self.l2_cache.stats()
        }


# å…¨å±€ç¼“å­˜å®ä¾‹
default_cache = MultiLevelCache()


def cache_result(ttl: Optional[float] = None,
                 cache_instance: Optional[MultiLevelCache] = None,
                 key_func: Optional[Callable] = None):
    """
    ç¼“å­˜å‡½æ•°ç»“æœçš„è£…é¥°å™¨

    Args:
        ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´
        cache_instance: ç¼“å­˜å®ä¾‹
        key_func: è‡ªå®šä¹‰é”®ç”Ÿæˆå‡½æ•°
    """
    def decorator(func: Callable) -> Callable:
        cache = cache_instance or default_cache

        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                try:
                    # å°è¯•ç”Ÿæˆå“ˆå¸Œé”®
                    args_str = str(args)
                    kwargs_str = str(sorted(kwargs.items()))
                    cache_key = f"{func.__module__}.{func.__name__}:{hash((args_str, kwargs_str))}"
                except (TypeError, ValueError):
                    # å¦‚æœæ— æ³•å“ˆå¸Œï¼Œä½¿ç”¨å­—ç¬¦ä¸²è¡¨ç¤º
                    cache_key = f"{func.__module__}.{func.__name__}:{str(args)}:{str(kwargs)}"

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = cache.get(cache_key)
            if cached_result is not None:
                return cached_result

            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = func(*args, **kwargs)
            cache.put(cache_key, result)

            return result

        # æ·»åŠ ç¼“å­˜ç®¡ç†æ–¹æ³•
        wrapper.cache_clear = lambda: cache.clear()
        wrapper.cache_stats = lambda: cache.stats()

        return wrapper

    return decorator


def memoize(func: Callable) -> Callable:
    """ç®€å•çš„è®°å¿†åŒ–è£…é¥°å™¨"""
    cache = {}

    @wraps(func)
    def wrapper(*args, **kwargs):
        key = (args, tuple(sorted(kwargs.items())))

        if key not in cache:
            cache[key] = func(*args, **kwargs)

        return cache[key]

    wrapper.cache_clear = lambda: cache.clear()
    wrapper.cache_info = lambda: {'size': len(cache)}

    return wrapper


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self):
        self.caches: Dict[str, Union[LRUCache,
                                     FileCache, MultiLevelCache]] = {}

    def create_cache(self, name: str, cache_type: str = 'lru', **kwargs) -> Union[LRUCache, FileCache, MultiLevelCache]:
        """åˆ›å»ºç¼“å­˜å®ä¾‹"""
        if cache_type == 'lru':
            cache = LRUCache(**kwargs)
        elif cache_type == 'file':
            cache = FileCache(**kwargs)
        elif cache_type == 'multi':
            cache = MultiLevelCache(**kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç¼“å­˜ç±»å‹: {cache_type}")

        self.caches[name] = cache
        return cache

    def get_cache(self, name: str) -> Optional[Union[LRUCache, FileCache, MultiLevelCache]]:
        """è·å–ç¼“å­˜å®ä¾‹"""
        return self.caches.get(name)

    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        for cache in self.caches.values():
            cache.clear()

    def get_all_stats(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰ç¼“å­˜çš„ç»Ÿè®¡ä¿¡æ¯"""
        return {name: cache.stats() for name, cache in self.caches.items()}

    def print_stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“¦ ç¼“å­˜ç³»ç»Ÿç»Ÿè®¡")
        print("=" * 50)

        for name, cache in self.caches.items():
            print(f"\nğŸ—‚ï¸ ç¼“å­˜: {name}")
            stats = cache.stats()

            if isinstance(cache, LRUCache):
                print(f"  ç±»å‹: å†…å­˜LRUç¼“å­˜")
                print(f"  å¤§å°: {stats['size']}/{stats['max_size']}")
                print(f"  å‘½ä¸­ç‡: {stats['hit_rate']:.2%}")
                print(f"  å‘½ä¸­æ¬¡æ•°: {stats['hits']}")
                print(f"  æœªå‘½ä¸­æ¬¡æ•°: {stats['misses']}")

            elif isinstance(cache, FileCache):
                print(f"  ç±»å‹: æ–‡ä»¶ç¼“å­˜")
                print(f"  æ–‡ä»¶æ•°: {stats['file_count']}")
                print(
                    f"  å¤§å°: {stats['total_size_mb']:.1f}/{stats['max_size_mb']:.1f}MB")
                print(f"  ç›®å½•: {stats['cache_dir']}")

            elif isinstance(cache, MultiLevelCache):
                print(f"  ç±»å‹: å¤šçº§ç¼“å­˜")
                l1_stats = stats['l1_cache']
                l2_stats = stats['l2_cache']
                print(
                    f"  L1ç¼“å­˜: {l1_stats['size']}/{l1_stats['max_size']} (å‘½ä¸­ç‡: {l1_stats['hit_rate']:.2%})")
                print(
                    f"  L2ç¼“å­˜: {l2_stats['file_count']}ä¸ªæ–‡ä»¶, {l2_stats['total_size_mb']:.1f}MB")


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨
cache_manager = CacheManager()

# åˆ›å»ºé»˜è®¤ç¼“å­˜å®ä¾‹
cache_manager.create_cache('default', 'multi')
cache_manager.create_cache('stock_data', 'multi', l1_size=500, l2_size_mb=50)
cache_manager.create_cache('strategy_results', 'lru',
                           max_size=100, ttl=1800)  # 30åˆ†é’Ÿ
